{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Amazon SageMaker Object Detection For Playing Cards\n",
    "\n",
    "# Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Data Exploration](#Data-Exploration)\n",
    "\n",
    "## Introduction\n",
    "In this workshop, you will learn how to use machine learning and computer vision to detection the rank and suit of playing cards from a [Standard 52-card deck](https://en.wikipedia.org/wiki/Standard_52-card_deck). We'll use cloud services from AWS to develop, train, and deploy for prediction a deep neural network model in under an hour.\n",
    "\n",
    "Object detection is the process of identifying and localizing objects in an image. A typical object detection solution takes an image as input and provides a bounding box on the image where an object of interest is found. It also identifies what type of object the box encapsulates. To create such a solution, we need to acquire and process a traning dataset, create and setup a training job for the alorithm so that it can learn about the dataset. Finally, we can then host the trained model in an endpoint, to which we can supply images.\n",
    "\n",
    "We provide a training set of 5,000 images of playing cards in Amazon S3 that are synthetically displayed with different backgrounds, rotation, zoom, and other image augmentation techniques. This notebook is an end-to-end example showing how the Amazon SageMaker Object Detection algorithm can be used such playing card images to detect playing cards on a blackjack table.  Amazon SageMaker's object detection algorithm uses the Single Shot multibox Detector [(SSD)](https://arxiv.org/abs/1512.02325) algorithm, and this notebook uses a [ResNet](https://arxiv.org/pdf/1603.05027.pdf) base network with that algorithm.\n",
    "\n",
    "![Photo of card predictions plot](./cardsplot.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before inspecting and understanding the data, there are some initial steps to prepare the underlying notebook instance with additional Python libraries.\n",
    "\n",
    "* **jsonlines** is used for easy interaction with JSON records stored as lines in a file. In this workshop, we use a SageMaker object detection [Augmented Manifest](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html#object-detection-augmented-manifest-training) file, allowing SageMaker to stream training data into the training job using Pipe Input mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the S3 bucket where the training data is stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_training = 'remars2019-revegas-trainingdata'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Object Detection algorithm on Amazon SageMaker, we need to setup and authenticate the use of AWS services. To begin with, we need an AWS account role with SageMaker access. Here we will use the execution role the current notebook instance was given when it was created. This role has necessary permissions, including access to your data in S3.\n",
    "\n",
    "We also import other libraries we need for the rest of the workshop to keep things organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15.5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by inspecting the annotated (labelled) data provided for the workshop.\n",
    "\n",
    "1. First, we'll download the Augmented Manifest file, which is a text file storing JSON objects on new lines. It stores references to image locations in S3, as well as the corresponding labels of suit and rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket_training).download_file(\n",
    "    'manifests/augmentedManifest.json',\n",
    "    './full_manifest.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We'll visualize the training data distribution and make sure our classes are balanced. SageMaker uses a key-value map to pass labels as classes to a neural network model. We defined those statically below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\"AC\": 0, \"2C\": 1, \"3C\": 2, \"4C\": 3, \"5C\": 4, \"6C\": 5, \"7C\": 6, \"8C\": 7, \"9C\": 8, \"10C\": 9, \"JC\": 10, \n",
    "             \"QC\": 11,\"KC\": 12, \"AD\": 13, \"2D\": 14, \"3D\": 15, \"4D\": 16, \"5D\": 17, \"6D\": 18, \"7D\": 19, \"8D\": 20, \n",
    "             \"9D\": 21, \"10D\": 22, \"JD\":23, \"QD\": 24, \"KD\": 25, \"AH\": 26, \"2H\": 27, \"3H\": 28, \"4H\": 29, \"5H\": 30, \n",
    "             \"6H\": 31, \"7H\": 32, \"8H\": 33, \"9H\": 34, \"10H\": 35, \"JH\": 36, \"QH\": 37, \"KH\": 38, \"AS\": 39, \"2S\": 40, \n",
    "             \"3S\": 41, \"4S\": 42, \"5S\": 43, \"6S\": 44, \"7S\": 45, \"8S\": 46, \"9S\": 47, \"10S\": 48, \"JS\": 49, \"QS\": 50, \"KS\": 51}\n",
    "object_categories = list(class_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(val): \n",
    "    for key, value in class_map.items(): \n",
    "         if val == value: \n",
    "             return key \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "labels = []\n",
    "train_df = pd.read_json('full_manifest.json', lines=True)\n",
    "# train_df['bounding-box'].values\n",
    "for x in train_df['bounding-box'].values:\n",
    "    for n in x['annotations']:\n",
    "        # print(get_key(n['class_id']))\n",
    "        labels.append(get_key(n['class_id']))\n",
    "        \n",
    "labels, values = zip(*Counter(labels).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's randomly display a training image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_manifest = []\n",
    "\n",
    "with jsonlines.open('full_manifest.json') as reader:\n",
    "    for obj in reader:\n",
    "        whole_manifest.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_train_img(whole_manifest):\n",
    "    random_annotation = whole_manifest[random.randint(0,4999)]\n",
    "    s3_uri = random_annotation['source-ref']\n",
    "   \n",
    "    s3_key = os.path.basename(s3_uri)\n",
    "    if 'images' not in os.listdir('.'):\n",
    "        os.mkdir('./images')\n",
    "    s3.Bucket(bucket_training).download_file(\n",
    "    s3_key, './images/' + s3_key)\n",
    "    raw_img = mpimg.imread('images/' + s3_key)\n",
    "    plt.imshow(raw_img)\n",
    "\n",
    "display_train_img(whole_manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have synthetically generated a training set of 5000 images using data augmentation techniques. By copying a cropped playing card onto various backgrounds and applying image filters such as blur and jpeg compression, the model should be much more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Now that we have inspected the data, let's perform a few steps to get the data ready to train on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(whole_manifest)\n",
    "\n",
    "count_samples = 0\n",
    "for x in whole_manifest:\n",
    "    count_samples = count_samples+1\n",
    "    \n",
    "print(\"Total samples: {}\".format(count_samples))\n",
    "\n",
    "train_count = round(count_samples * 0.04)\n",
    "val_count = round(count_samples * 0.004)\n",
    "test_count = round(count_samples * 0.002)\n",
    "print(\"Train count: \" + str(train_count) + '\\n' +\\\n",
    "      \"Validation count: \" + str(val_count)  + '\\n' +\\\n",
    "      \"Test count: \" + str(test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_manifest = []\n",
    "for i in range(train_count):\n",
    "    train_manifest.append(whole_manifest.pop())\n",
    "    \n",
    "val_manifest = []\n",
    "for i in range(val_count):\n",
    "    val_manifest.append(whole_manifest.pop())\n",
    "    \n",
    "test_manifest = []\n",
    "for i in range(test_count):\n",
    "    test_manifest.append(whole_manifest.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('train.manifest', mode='w') as writer:\n",
    "    for i in train_manifest:\n",
    "        writer.write(i)\n",
    "        \n",
    "with jsonlines.open('validate.manifest', mode='w') as writer:\n",
    "    for i in val_manifest:\n",
    "        writer.write(i)\n",
    "        \n",
    "with jsonlines.open('test.manifest', mode='w') as writer:\n",
    "    for i in test_manifest:\n",
    "        writer.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the manifests to a location in S3 to be used in the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.upload_data(path='train.manifest', key_prefix='manifests')\n",
    "sess.upload_data(path='validate.manifest', key_prefix='manifests')\n",
    "\n",
    "s3_train_data = 's3://{}/manifests/{}'.format(sess.default_bucket(), 'train.manifest')\n",
    "s3_validation_data = 's3://{}/manifests/{}'.format(sess.default_bucket(), 'validate.manifest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In the following steps, you will incrementally train a model that we trained in advance over hundreds of thousands of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_path = 's3://{}/card-detection-output/'.format(sess.default_bucket())\n",
    "\n",
    "# Model URI to our previously trained model:\n",
    "model_uri = 's3://remars2019-revegas-trainingdata/model.tar.gz'\n",
    "\n",
    "# Training container image that has the built-in SageMaker algorithm:\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'object-detection', repo_version='latest')\n",
    "\n",
    "# Create the sagemaker estimator object.\n",
    "playing_card_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count = 1, \n",
    "                                         train_instance_type = 'ml.p2.xlarge',\n",
    "                                         input_mode='Pipe',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         output_path = s3_output_path,\n",
    "                                         base_job_name = 'playingcard-bbox',\n",
    "                                         sagemaker_session = sess,\n",
    "                                         model_uri=model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters \n",
    "playing_card_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             kv_store='dist_sync',\n",
    "                             mini_batch_size=16,\n",
    "                             use_pretrained_model=1,                          \n",
    "                             num_classes=52, # suit/rank combinations\n",
    "                             epochs=30,\n",
    "                             image_shape=512,\n",
    "                             num_training_samples = train_count,\n",
    "                             learning_rate=0.00001,                             \n",
    "                             optimizer='sgd',\n",
    "                             early_stopping=False,\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             lr_scheduler_step='20,25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sagemaker s3_input objects\n",
    "\n",
    "attribute_names = [\"source-ref\",\"bounding-box\"]\n",
    "distribution = 'FullyReplicated'\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution=distribution, \n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        attribute_names=attribute_names,\n",
    "                                        s3_data_type='AugmentedManifestFile')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution=distribution, \n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        attribute_names=attribute_names,\n",
    "                                        s3_data_type='AugmentedManifestFile')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "playing_card_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_predictor = playing_card_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_predictor.content_type('image/jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_test_img(test_manifest):\n",
    "    random_annotation = test_manifest[random.randint(0,test_count-1)]\n",
    "    s3_uri = random_annotation['source-ref']\n",
    "    annotations = random_annotation['bounding-box']['annotations']\n",
    "    \n",
    "    s3_key = os.path.basename(s3_uri)\n",
    "    s3.Bucket(bucket_training).download_file(\n",
    "    s3_key, 'images/' + s3_key)\n",
    "    raw_img = mpimg.imread('images/' + s3_key)\n",
    "    plt.imshow(raw_img)\n",
    "    return s3_key\n",
    "\n",
    "print(s3_key)\n",
    "s3_key = display_test_img(test_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(s3_key):\n",
    "    img_bytes = io.BytesIO()\n",
    "    s3.Object(bucket_training, s3_key).download_fileobj(img_bytes)\n",
    "    \n",
    "    dets = json.loads(pcm_predictor.predict(img_bytes.getvalue()))\n",
    "    return dets['prediction'], img_bytes\n",
    "\n",
    "def visualize_detection(img_file, dets, classes=[], thresh=0.4):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "\n",
    "        img = mpimg.imread(img_file, \"jpg\")\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width  = img.shape[1]\n",
    "        colors = dict()\n",
    "        num_detections = 0\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            num_detections += 1\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id], linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            print('{},{}'.format(class_name,score))\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "\n",
    "        print('Number of detections: ' + str(num_detections))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections, img = generate_predictions(s3_key=s3_key)\n",
    "\n",
    "visualize_detection(img_file=img, dets=detections, classes=object_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the model file accessible so that workshop leads can add your model to the blackjack table system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "print(playing_card_model.model_data)\n",
    "o = urlparse(playing_card_model.model_data)\n",
    "\n",
    "s3object = s3.Object(o.netloc,o.path.lstrip('/'))\n",
    "\n",
    "print(o.netloc)\n",
    "print(o.path.lstrip('/'))\n",
    "                     \n",
    "\n",
    "s3object.copy_from(\n",
    "    ACL=\"public-read\",\n",
    "    CopySource={\"Bucket\": o.netloc,\n",
    "                \"Key\": o.path.lstrip('/')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
